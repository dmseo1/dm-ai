{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"./dataset\")\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from dataset.mnist import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_image_data, train_label_data), (test_image_data, test_label_data) = load_mnist(flatten = True, normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_image_data.shape)\n",
    "print(train_label_data.shape)\n",
    "print(test_image_data.shape)\n",
    "print(test_label_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = train_image_data[0]\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_reshaped = image.reshape(28, 28)\n",
    "image_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "label = train_label_data[0]\n",
    "plt.figure(figsize = (4, 4))\n",
    "plt.title(\"sample of \" + str(label))\n",
    "plt.imshow(image_reshaped, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "def mnist_show(n) :\n",
    "    image = train_image_data[n]\n",
    "    image_reshaped = image.reshape(28, 28)\n",
    "    image_reshaped.shape\n",
    "    label = train_label_data[n]\n",
    "    plt.figure(figsize = (4, 4))\n",
    "    plt.title(\"sample of \" + str(label))\n",
    "    plt.imshow(image_reshaped, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_show(2747)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x) :\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(matrix) :\n",
    "    maximum_of_matrix = np.max(matrix)\n",
    "    difference_from_maximum = matrix - maximum_of_matrix\n",
    "    exponential_of_difference = np.exp(difference_from_maximum)\n",
    "    sum_of_exponential = np.sum(exponential_of_difference)\n",
    "    y = exponential_of_difference / sum_of_exponential\n",
    "    return y\n",
    "\n",
    "def get_data():\n",
    "    (image_train, label_train), (image_test, label_test) = load_mnist(flatten=True, normalize=False)\n",
    "    return image_test, label_test\n",
    "\n",
    "def init_network() :\n",
    "    with open('./dataset/sample_weight.pkl', 'rb') as f:\n",
    "        network = pickle.load(f)\n",
    "    return network\n",
    "\n",
    "def predict(network, x) :\n",
    "    # hidden data 2개\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = softmax(a3)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9207\n"
     ]
    }
   ],
   "source": [
    "images, labels = get_data()\n",
    "network = init_network()\n",
    "\n",
    "accuracy_cnt = 0\n",
    "for i in range(len(images)) :\n",
    "    y = predict(network, images[i]) #output 10개를 가져온다(0~9 10개의 수에 대한 확률)\n",
    "    p = np.argmax(y) # 가장 가능성이 높은 p를 추출\n",
    "    if p == labels[i] : # 실제 값과 비교하여 카운트\n",
    "        accuracy_cnt += 1\n",
    "    \n",
    "print(\"Accuracy: \" + str(float(accuracy_cnt) / len(images)))\n",
    "\n",
    "#output이 0개가 되는 과정\n",
    "# 1 * 784, 784 * 50, 50 * 100, 100 * 10  => 1 * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9207\n"
     ]
    }
   ],
   "source": [
    "#배치처리\n",
    "images, labels = get_data()\n",
    "network = init_network()\n",
    "\n",
    "batch_size = 100\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(0, len(images), batch_size) :\n",
    "    x_batch = images[i:i + batch_size]\n",
    "    y_batch = predict(network, x_batch)\n",
    "    p = np.argmax(y_batch, axis=1)\n",
    "    accuracy_cnt += np.sum(p == labels[i:i+batch_size])\n",
    "    \n",
    "print(\"Accuracy: \" + str(float(accuracy_cnt) / len(images)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "true = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "def mean_squared_error(y, t):\n",
    "    return 0.5 * np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09750000000000003"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(np.array(y), np.array(true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5975"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "mean_squared_error(np.array(y), np.array(true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta)) # delta가 있는 이유: log 0 = -무한대 이므로, 이를 방지하기 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "true = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_error(np.array(y), np.array(true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302584092994546"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "cross_entropy_error(np.array(y), np.array(true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize = True, one_hot_label = True)\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size  = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3857, 59803, 34274, 14334, 40601, 54381, 17974, 52960,  7306,\n",
       "       42005])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(60000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot이 입력값으로 들어올 경우\n",
    "def cross_entropy_error_one_hot(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t * np.log(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label이 입력값으로 들어올 경우\n",
    "def cross_entropy_error_label(y, t) :\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    \n",
    "    batch_size = y.shape[0]\n",
    "    \n",
    "    #one hot 형태로 반환\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_differential(f, x) :\n",
    "    h = 1e-4\n",
    "    return ((f(x + h) - f(x - h)) / (2 * h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(x):\n",
    "    return 0.01*(x**2) + 0.2*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2999999999986347"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_differential(function_1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40000000000040004"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_differential(function_1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 편미분\n",
    "def function_2(x) :\n",
    "    return x[0] ** 2 + x[1] ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_3(x) :\n",
    "    return x*x + 4**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_4(x) :\n",
    "    return 3**2 + x*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.00000000000378"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_differential(function_3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.999999999999119"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_differential(function_4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, x) :\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    for index in range(x.size) : #x의 size는 독립변수의 개수를 의미\n",
    "        tmp_val = x[index]\n",
    "        x[index] = tmp_val + h #x의 한 독립변수를 약간 증가했을 때\n",
    "        fxh1 = f(x)             #그 상태를 저장한다\n",
    "        \n",
    "        x[index] = tmp_val - h #그 독립변수를 약간 감소시켰을 때\n",
    "        fxh2 = f(x)            #그 상태를 또 저장한다\n",
    "        \n",
    "        grad[index] = (fxh1 - fxh2) / (2*h) # 그 독립변수에 대한 기울기를 저장한다\n",
    "        x[index] = tmp_val                  #그 독립변수를 감소했던 것을 되돌린다\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 8.])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#기울기가 적게끔 매개변수를 변경해야 함\n",
    "numerical_gradient(function_2, np.array([3.0, 4.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 4.])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([0.0, 2.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 0.])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([3.0, 0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step num과 lr을 늘여보고 줄여보면서 최적화된 값이 나오도록 한다\n",
    "\n",
    "def gradient_descent(f, init_x, lr=0.01, step_num = 100) : # lr = learning rate: 학습률\n",
    "    x = init_x\n",
    "    x_history = []\n",
    "    \n",
    "    for i in range(step_num) :\n",
    "        x_history.append(x.copy())\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr * grad\n",
    "        print(x)\n",
    "    return x, np.array(x_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400.00000002 400.00000002]\n",
      "[320.00000007 320.00000007]\n",
      "[256.00000007 256.00000007]\n",
      "[204.80000007 204.80000007]\n",
      "[163.84000005 163.84000005]\n",
      "[131.07200004 131.07200004]\n",
      "[104.85760003 104.85760003]\n",
      "[83.88608002 83.88608002]\n",
      "[67.10886402 67.10886402]\n",
      "[53.68709121 53.68709121]\n",
      "[42.94967297 42.94967297]\n",
      "[34.35973838 34.35973838]\n",
      "[27.4877907 27.4877907]\n",
      "[21.99023256 21.99023256]\n",
      "[17.59218605 17.59218605]\n",
      "[14.07374884 14.07374884]\n",
      "[11.25899907 11.25899907]\n",
      "[9.00719926 9.00719926]\n",
      "[7.20575941 7.20575941]\n",
      "[5.76460752 5.76460752]\n",
      "[4.61168602 4.61168602]\n",
      "[3.68934882 3.68934882]\n",
      "[2.95147905 2.95147905]\n",
      "[2.36118324 2.36118324]\n",
      "[1.88894659 1.88894659]\n",
      "[1.51115727 1.51115727]\n",
      "[1.20892582 1.20892582]\n",
      "[0.96714066 0.96714066]\n",
      "[0.77371252 0.77371252]\n",
      "[0.61897002 0.61897002]\n",
      "[0.49517602 0.49517602]\n",
      "[0.39614081 0.39614081]\n",
      "[0.31691265 0.31691265]\n",
      "[0.25353012 0.25353012]\n",
      "[0.2028241 0.2028241]\n",
      "[0.16225928 0.16225928]\n",
      "[0.12980742 0.12980742]\n",
      "[0.10384594 0.10384594]\n",
      "[0.08307675 0.08307675]\n",
      "[0.0664614 0.0664614]\n",
      "[0.05316912 0.05316912]\n",
      "[0.0425353 0.0425353]\n",
      "[0.03402824 0.03402824]\n",
      "[0.02722259 0.02722259]\n",
      "[0.02177807 0.02177807]\n",
      "[0.01742246 0.01742246]\n",
      "[0.01393797 0.01393797]\n",
      "[0.01115037 0.01115037]\n",
      "[0.0089203 0.0089203]\n",
      "[0.00713624 0.00713624]\n",
      "[0.00570899 0.00570899]\n",
      "[0.00456719 0.00456719]\n",
      "[0.00365375 0.00365375]\n",
      "[0.002923 0.002923]\n",
      "[0.0023384 0.0023384]\n",
      "[0.00187072 0.00187072]\n",
      "[0.00149658 0.00149658]\n",
      "[0.00119726 0.00119726]\n",
      "[0.00095781 0.00095781]\n",
      "[0.00076625 0.00076625]\n",
      "[0.000613 0.000613]\n",
      "[0.0004904 0.0004904]\n",
      "[0.00039232 0.00039232]\n",
      "[0.00031386 0.00031386]\n",
      "[0.00025108 0.00025108]\n",
      "[0.00020087 0.00020087]\n",
      "[0.00016069 0.00016069]\n",
      "[0.00012856 0.00012856]\n",
      "[0.00010284 0.00010284]\n",
      "[8.22752279e-05 8.22752279e-05]\n",
      "[6.58201823e-05 6.58201823e-05]\n",
      "[5.26561458e-05 5.26561458e-05]\n",
      "[4.21249167e-05 4.21249167e-05]\n",
      "[3.36999333e-05 3.36999333e-05]\n",
      "[2.69599467e-05 2.69599467e-05]\n",
      "[2.15679573e-05 2.15679573e-05]\n",
      "[1.72543659e-05 1.72543659e-05]\n",
      "[1.38034927e-05 1.38034927e-05]\n",
      "[1.10427942e-05 1.10427942e-05]\n",
      "[8.83423533e-06 8.83423533e-06]\n",
      "[7.06738826e-06 7.06738826e-06]\n",
      "[5.65391061e-06 5.65391061e-06]\n",
      "[4.52312849e-06 4.52312849e-06]\n",
      "[3.61850279e-06 3.61850279e-06]\n",
      "[2.89480223e-06 2.89480223e-06]\n",
      "[2.31584179e-06 2.31584179e-06]\n",
      "[1.85267343e-06 1.85267343e-06]\n",
      "[1.48213874e-06 1.48213874e-06]\n",
      "[1.18571099e-06 1.18571099e-06]\n",
      "[9.48568795e-07 9.48568795e-07]\n",
      "[7.58855036e-07 7.58855036e-07]\n",
      "[6.07084029e-07 6.07084029e-07]\n",
      "[4.85667223e-07 4.85667223e-07]\n",
      "[3.88533779e-07 3.88533779e-07]\n",
      "[3.10827023e-07 3.10827023e-07]\n",
      "[2.48661618e-07 2.48661618e-07]\n",
      "[1.98929295e-07 1.98929295e-07]\n",
      "[1.59143436e-07 1.59143436e-07]\n",
      "[1.27314749e-07 1.27314749e-07]\n",
      "[1.01851799e-07 1.01851799e-07]\n",
      "[8.14814391e-08 8.14814391e-08]\n",
      "[6.51851513e-08 6.51851513e-08]\n",
      "[5.2148121e-08 5.2148121e-08]\n",
      "[4.17184968e-08 4.17184968e-08]\n",
      "[3.33747974e-08 3.33747974e-08]\n",
      "[2.6699838e-08 2.6699838e-08]\n",
      "[2.13598704e-08 2.13598704e-08]\n",
      "[1.70878963e-08 1.70878963e-08]\n",
      "[1.3670317e-08 1.3670317e-08]\n",
      "[1.09362536e-08 1.09362536e-08]\n",
      "[8.7490029e-09 8.7490029e-09]\n",
      "[6.99920232e-09 6.99920232e-09]\n",
      "[5.59936186e-09 5.59936186e-09]\n",
      "[4.47948949e-09 4.47948949e-09]\n",
      "[3.58359159e-09 3.58359159e-09]\n",
      "[2.86687327e-09 2.86687327e-09]\n",
      "[2.29349862e-09 2.29349862e-09]\n",
      "[1.83479889e-09 1.83479889e-09]\n",
      "[1.46783911e-09 1.46783911e-09]\n",
      "[1.17427129e-09 1.17427129e-09]\n",
      "[9.39417033e-10 9.39417033e-10]\n",
      "[7.51533627e-10 7.51533627e-10]\n",
      "[6.01226901e-10 6.01226901e-10]\n",
      "[4.80981521e-10 4.80981521e-10]\n",
      "[3.84785217e-10 3.84785217e-10]\n",
      "[3.07828173e-10 3.07828173e-10]\n",
      "[2.46262539e-10 2.46262539e-10]\n",
      "[1.97010031e-10 1.97010031e-10]\n",
      "[1.57608025e-10 1.57608025e-10]\n",
      "[1.2608642e-10 1.2608642e-10]\n",
      "[1.00869136e-10 1.00869136e-10]\n",
      "[8.06953087e-11 8.06953087e-11]\n",
      "[6.4556247e-11 6.4556247e-11]\n",
      "[5.16449976e-11 5.16449976e-11]\n",
      "[4.13159981e-11 4.13159981e-11]\n",
      "[3.30527984e-11 3.30527984e-11]\n",
      "[2.64422388e-11 2.64422388e-11]\n",
      "[2.1153791e-11 2.1153791e-11]\n",
      "[1.69230328e-11 1.69230328e-11]\n",
      "[1.35384262e-11 1.35384262e-11]\n",
      "[1.0830741e-11 1.0830741e-11]\n",
      "[8.6645928e-12 8.6645928e-12]\n",
      "[6.93167424e-12 6.93167424e-12]\n",
      "[5.54533939e-12 5.54533939e-12]\n",
      "[4.43627151e-12 4.43627151e-12]\n",
      "[3.54901721e-12 3.54901721e-12]\n",
      "[2.83921377e-12 2.83921377e-12]\n",
      "[2.27137101e-12 2.27137101e-12]\n",
      "[1.81709681e-12 1.81709681e-12]\n",
      "[1.45367745e-12 1.45367745e-12]\n",
      "[1.16294196e-12 1.16294196e-12]\n",
      "[9.30353567e-13 9.30353567e-13]\n",
      "[7.44282853e-13 7.44282853e-13]\n",
      "[5.95426283e-13 5.95426283e-13]\n",
      "[4.76341026e-13 4.76341026e-13]\n",
      "[3.81072821e-13 3.81072821e-13]\n",
      "[3.04858258e-13 3.04858258e-13]\n",
      "[2.43886607e-13 2.43886607e-13]\n",
      "[1.95109286e-13 1.95109286e-13]\n",
      "[1.5608743e-13 1.5608743e-13]\n",
      "[1.24869943e-13 1.24869943e-13]\n",
      "[9.98959562e-14 9.98959562e-14]\n",
      "[7.99167643e-14 7.99167643e-14]\n",
      "[6.39334122e-14 6.39334122e-14]\n",
      "[5.11467302e-14 5.11467302e-14]\n",
      "[4.0917383e-14 4.0917383e-14]\n",
      "[3.27339057e-14 3.27339057e-14]\n",
      "[2.61871243e-14 2.61871243e-14]\n",
      "[2.09496988e-14 2.09496988e-14]\n",
      "[1.67597585e-14 1.67597585e-14]\n",
      "[1.34078067e-14 1.34078067e-14]\n",
      "[1.07262435e-14 1.07262435e-14]\n",
      "[8.58099445e-15 8.58099445e-15]\n",
      "[6.86479403e-15 6.86479403e-15]\n",
      "[5.49183634e-15 5.49183634e-15]\n",
      "[4.3934687e-15 4.3934687e-15]\n",
      "[3.51477376e-15 3.51477376e-15]\n",
      "[2.81181831e-15 2.81181831e-15]\n",
      "[2.24945378e-15 2.24945378e-15]\n",
      "[1.7995643e-15 1.7995643e-15]\n",
      "[1.43965223e-15 1.43965223e-15]\n",
      "[1.15172058e-15 1.15172058e-15]\n",
      "[9.21376427e-16 9.21376427e-16]\n",
      "[7.37099612e-16 7.37099612e-16]\n",
      "[5.8968031e-16 5.8968031e-16]\n",
      "[4.7174338e-16 4.7174338e-16]\n",
      "[3.77392678e-16 3.77392678e-16]\n",
      "[3.01913274e-16 3.01913274e-16]\n",
      "[2.41531571e-16 2.41531571e-16]\n",
      "[1.9322505e-16 1.9322505e-16]\n",
      "[1.54581653e-16 1.54581653e-16]\n",
      "[1.23665778e-16 1.23665778e-16]\n",
      "[9.89322505e-17 9.89322505e-17]\n",
      "[7.9145263e-17 7.9145263e-17]\n",
      "[6.33155077e-17 6.33155077e-17]\n",
      "[5.06521997e-17 5.06521997e-17]\n",
      "[4.05233731e-17 4.05233731e-17]\n",
      "[3.24194846e-17 3.24194846e-17]\n",
      "[2.59352158e-17 2.59352158e-17]\n",
      "[2.07479662e-17 2.07479662e-17]\n",
      "[1.6598001e-17 1.6598001e-17]\n",
      "[1.32776981e-17 1.32776981e-17]\n",
      "[1.06216211e-17 1.06216211e-17]\n",
      "[8.49659411e-18 8.49659411e-18]\n",
      "[6.79673795e-18 6.79673795e-18]\n",
      "[5.43602584e-18 5.43602584e-18]\n",
      "[4.34911052e-18 4.34911052e-18]\n",
      "[3.4797437e-18 3.4797437e-18]\n",
      "[2.78243044e-18 2.78243044e-18]\n",
      "[2.22739225e-18 2.22739225e-18]\n",
      "[1.78319626e-18 1.78319626e-18]\n",
      "[1.42502705e-18 1.42502705e-18]\n",
      "[1.14047692e-18 1.14047692e-18]\n",
      "[9.13002255e-19 9.13002255e-19]\n",
      "[7.31849701e-19 7.31849701e-19]\n",
      "[5.85438733e-19 5.85438733e-19]\n",
      "[4.68806267e-19 4.68806267e-19]\n",
      "[3.73680496e-19 3.73680496e-19]\n",
      "[2.9840706e-19 2.9840706e-19]\n",
      "[2.38850056e-19 2.38850056e-19]\n",
      "[1.900464e-19 1.900464e-19]\n",
      "[1.52823273e-19 1.52823273e-19]\n",
      "[1.2304477e-19 1.2304477e-19]\n",
      "[9.90565327e-20 9.90565327e-20]\n",
      "[8.00313786e-20 8.00313786e-20]\n",
      "[6.4314947e-20 6.4314947e-20]\n",
      "[5.02528766e-20 5.02528766e-20]\n",
      "[3.94995286e-20 3.94995286e-20]\n",
      "[3.20549031e-20 3.20549031e-20]\n",
      "[2.62646388e-20 2.62646388e-20]\n",
      "[2.04743745e-20 2.04743745e-20]\n",
      "[1.46841102e-20 1.46841102e-20]\n",
      "[1.22025684e-20 1.22025684e-20]\n",
      "[9.72102656e-21 9.72102656e-21]\n",
      "[7.23948472e-21 7.23948472e-21]\n",
      "[4.75794288e-21 4.75794288e-21]\n",
      "[4.75794288e-21 4.75794288e-21]\n",
      "[4.75794288e-21 4.75794288e-21]\n",
      "[4.75794288e-21 4.75794288e-21]\n",
      "[4.75794288e-21 4.75794288e-21]\n",
      "[4.75794288e-21 4.75794288e-21]\n",
      "[4.75794288e-21 4.75794288e-21]\n",
      "[4.75794288e-21 4.75794288e-21]\n",
      "[4.75794288e-21 4.75794288e-21]\n",
      "[4.75794288e-21 4.75794288e-21]\n",
      "[4.75794288e-21 4.75794288e-21]\n",
      "[4.75794288e-21 4.75794288e-21]\n",
      "[4.75794288e-21 4.75794288e-21]\n",
      "[4.75794288e-21 4.75794288e-21]\n",
      "[4.75794288e-21 4.75794288e-21]\n",
      "[4.75794288e-21 4.75794288e-21]\n"
     ]
    }
   ],
   "source": [
    "init_x = np.array([500.0, 500.0])\n",
    "lr = 0.1\n",
    "step_num = 250\n",
    "x, x_history = gradient_descent(function_2, init_x, lr=lr, step_num=step_num)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta))\n",
    "\n",
    "def numerical_gradient(f, x) :\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x)\n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleNet :\n",
    "    def __init__(self) :\n",
    "        self.W = np.random.randn(2, 3)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.06433458  0.75626655 -0.51066919]\n",
      " [ 1.57636072 -1.21827724  1.56343071]]\n"
     ]
    }
   ],
   "source": [
    "net = simpleNet()\n",
    "print(net.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.38012391 -0.64268959  1.10068613]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0.6, 0.9]) # 0.6과 0.9는 예측값\n",
    "p = net.predict(x)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(p) # p 값들 중에서 몇 번째에 있는 것이 가장 높은지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9152159145926789"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array([0, 0, 1])\n",
    "net.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(W):\n",
    "    return net.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.31771381  0.0420294  -0.35973323]\n",
      " [ 0.47657072  0.0630451  -0.53959337]]\n"
     ]
    }
   ],
   "source": [
    "dW = numerical_gradient(f, net.W)\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.31771381  0.0420294  -0.35973323]\n",
      " [ 0.47657072  0.0630451  -0.53959337]]\n"
     ]
    }
   ],
   "source": [
    "f = lambda w : net.loss(x, t)\n",
    "dW = numerical_gradient(f, net.W)\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_function(x):\n",
    "    return np.array(x > 0, dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_grad(x):\n",
    "    return (1.0 - sigmoid(x)) * sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_grad(x):\n",
    "    grad = np.zeros(x)\n",
    "    grad[x>=0] = 1\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T\n",
    "    x = x - np.max(x)\n",
    "    return np.exp(x) / np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y, t):\n",
    "    return 0.5 * np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_loss(X, t):\n",
    "    y = softmax(X)\n",
    "    return cross_entropy_error(y, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "        self.count = 0\n",
    "    \n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        return y\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "    \n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W : self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        grads = {}\n",
    "        \n",
    "        batch_num = x.shape[0]\n",
    "        \n",
    "        #forward\n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        #backward\n",
    "        dy = (y - t) / batch_num\n",
    "        grads['W2'] = np.dot(z1.T, dy)\n",
    "        grads['b2'] = np.sum(dy, axis = 0)\n",
    "        \n",
    "        dz1 = np.dot(dy, W2.T)\n",
    "        da1 = sigmoid_grad(a1) * dz1\n",
    "        grads['W1'] = np.dot(x.T, da1)\n",
    "        grads['b1'] = np.sum(da1, axis=0)\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50)\n",
      "(50,)\n",
      "(50, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(net.params['W1'].shape)\n",
    "print(net.params['b1'].shape)\n",
    "print(net.params['W2'].shape)\n",
    "print(net.params['b2'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(100, 784)\n",
    "y = net.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-209-2a20aa2bdf14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-205-f77750a80791>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-188-7802f36f3c06>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[1;34m(f, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_val\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mfxh2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfxh1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfxh2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miternext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(100, 784)\n",
    "t = np.random.rand(100, 10)\n",
    "\n",
    "net.numerical_gradient(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
